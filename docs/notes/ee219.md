以下是润色后的版本，衔接更加流畅，用语更加自然，同时保留逻辑清晰性和条理性：

---

# 在智能计算系统的项目中，我们能做些什么？

核心目标是设计**自定义指令**，实现上层 AI 应用与硬件之间的高效交互。

---

## 软件部分

1. **基础实现**  
   即便完全不使用自定义指令，也可以完成推理任务，例如运行经典的 LeNet 模型。然而，这种方式会消耗更多的时间周期，性能较低。

2. **优化实现**  
   使用自定义指令能够显著加速运算，例如指导硬件模块加速矩阵计算的核心任务。

具体步骤包括：
- 设计自定义指令集，用以支持矩阵运算、卷积等关键功能。
- 将这些自定义指令通过内联汇编封装成函数接口。
- 利用这些接口，将原生的 C 语言实现改写为支持自定义指令的版本，从而充分利用硬件加速能力。

---

## 硬件部分

为了支持自定义指令，我们需要在硬件中完成以下模块的实现：
- **卷积层**：处理输入特征图和卷积核的矩阵运算。
- **ReLU 层**：激活函数模块，用于非线性变换。
- **全连接层**：实现网络的分类或回归任务。

这些模块共同组成了支持自定义指令的硬件计算框架。

---

## 构建流程

当我们运行 `make run CFILE=xxx` 命令时，实际发生了以下几步操作：

1. **构建处理器（build）**  
   使用 Verilator 将 Verilog 描述的处理器转化为 C++ 仿真模型，同时链接 C++ 激励文件以生成可执行仿真程序。

2. **生成参考结果（model）**  
   使用 Python 脚本运行软件模型，生成用于对比的黄金标准结果。

3. **编译 C 程序（compile）**  
   借助 AM 框架，将 C 源代码编译为汇编指令，并提取出指令二进制文件以供硬件仿真使用。

最后，仿真程序会加载指定的参数运行，并验证仿真结果是否符合预期。

---

## 方法论

`model.h` 文件中没有任何注释，这给调试带来了极大的困扰——一不留神就可能搞不清楚权重参数到底存储在哪里。

---

## 原始软件实现

在 `model.py` 中，我们依次完成了以下任务：
1. **加载预训练参数**  
   包括每一层的权重参数（`weights`）、输入量化比例（`input_scale`）以及输出量化比例（`output_scale`）。

2. **运行推理并保存中间结果**  
   使用加载的模型对 CIFAR 数据集中的一张图片进行推理，同时在推理过程中将每一层的中间计算结果保存为 `.npy` 文件（如 `xxx.npy`），便于后续分析。

3. **导出量化权重和缩放因子**  
   遍历每一层的参数，将权重量化到 8-bit，并将缩放因子调整为 2 的幂，最终将这些数据保存为二进制文件（`xxx.bin`），供硬件加载使用。

---

## 硬件仿真测试

为了在 C 程序中实现与 `model.py` 等价的功能，我们需要解决一些关键问题。

### 问题：如何在 C 程序中获取权重参数？
由于 AM 框架不支持直接从文件中读取权重参数，这需要通过以下方法解决：

- AM 框架的内存访问依赖于 DPI-C 接口实现。这意味着权重参数需要预先加载到一个模拟框架提供的 C 数组中。
- `xxx.bin` 文件中的数据已加载到这个 C 数组中，数据的基地址由宏 `ADDR_DATA` 定义。
- 文件 `model.h` 提供了每一层参数起始地址的宏定义，通过这些宏可以准确定位各层的权重和偏置数据。

---

## 加速！

通过定义自定义指令并结合硬件支持，我们可以高效完成推理任务，从而显著提升模型的运行速度。

---

