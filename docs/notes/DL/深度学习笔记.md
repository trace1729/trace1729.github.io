${toc}

```json
 
```

## æœ¯è¯­

| zh       | en              |      |
|----------|-----------------|------|
| å¼ é‡     | Tensor          | <++> |
| æ ‡é‡å‡½æ•° | Scalar fucntion | <++> |
| å…¨è¿æ¥å±‚ | full connected layer |  è¾“å‡ºå±‚ä¸­çš„ç¥ç»å…ƒå’Œè¾“â¼Šå…¥å±‚ä¸­å„ä¸ªè¾“â¼Šå…¥å®Œå…¨è¿
æ¥|
| ç‰¹å¾ | feature | é¢„æµ‹æ ‡ç­¾çš„å› å­ (æƒé‡) |
| æ ‡ç­¾ | label | çœŸå®å€¼ |



## DL Lec 1

**some concepts** 

- `deep learning` is a subset of `machine learning`
- `machine learning` is a subset of `artificial intelligence`


The difference between DL and traditional ML

- æ·±åº¦å­¦ä¹ ä¸éœ€è¦äººå·¥æå–ç‰¹å¾ï¼Œä¼ ç»Ÿæœºå™¨å­¦ä¹ éœ€è¦ 

**Important factors(å…³é”®è¦ç´ )** 

- æ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹
- å¤§è§„æ¨¡æ•°æ®é›†
- å¤§è§„æ¨¡è®¡ç®—èµ„æº 

> Q: è§£é‡Šæ·±åº¦å­¦ä¹ è¿‘å‡ å¹´ç«çˆ†çš„åŸå›  <br>
> A: éšç€äº’è”ç½‘çš„å‘å±•ï¼Œç½‘ç»œä¸Šçš„è¯­æ–™å’Œè§†é¢‘æ•°æ®è¶³å¤Ÿåºå¤§
>     <br> GPU çš„ç®—åŠ›é€å¹´å¢é•¿ 


**Classifying dataset** 

1. tranning Set
2. validating Set
3. test Set 

**genenralization (æ³›åŒ–)** 

- è¿‡æ‹Ÿåˆ æ³›åŒ–è¯¯å·®å¤§  
- æ¬ æ‹Ÿåˆ è®­ç»ƒé›†ä¸Šå’Œæµ‹è¯•é›†ä¸Šæ•ˆæœéƒ½å·®  

![generlization](../img/generlization.png)

## lab1 ç¯å¢ƒé…ç½®

- é¦–å…ˆéœ€è¦è£… `anaconda`  

`yay -S anaconda`

- æ¢æº

```
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
conda config --set show_channel_urls yes
```

- åŠ è½½é…ç½®æ–‡ä»¶ 

`source /opt/anaconda/bin/activate root`


- å®‰è£… `pytorch` çš„åº“

![pytorch](../img/pytorch.png)

æ³¨æ„åŠ ä¸Š `sudo` å› ä¸ºè¦å¯¹ `/opt` ç›®å½•è¿›è¡Œå†™å…¥æ“ä½œ

- æµ‹è¯• minst æ•°æ®é›†


## **åŠ¨æ‰‹å­¦ä¹ æ·±åº¦å­¦ä¹ ç¬¬äºŒç« ** 

## Lec 3 ç¥ç»ç½‘ç»œç®€ä»‹


**ç¥ç»ç½‘ç»œåŸºæœ¬ç»“æ„** 

- è¾“å…¥å±‚ã€‚è¡¨ç¤ºåŸå§‹è¾“å…¥æ•°æ®ï¼Œä¸€èˆ¬åªæœ‰ä¸€å±‚, è¾“å…¥ç¬¬ä¸€å±‚è®°ä¸ºç¥ç»ç½‘ç»œçš„ç¬¬0å±‚
- éšè—å±‚ã€‚å¯¹è¾“å…¥æ•°æ®è¿›è¡Œ **éçº¿æ€§å˜æ¢** ,ä»¥è¿›è¡Œ*ç‰¹å¾æå–å’ŒåŠ å·¥*ï¼Œä¸€èˆ¬æœ‰å¤šä¸ªéšè—å±‚ã€‚
ç¬¬ä¸€ä¸ªéšè—å±‚è®°ä¸ºç¥ç»ç½‘ç»œçš„ç¬¬ä¸€å±‚
- è¾“å‡ºå±‚ã€‚è¡¨ç¤ºåˆ†ç±»çš„ç»“æœã€‚è¦åˆ†æˆå‡ ç±»ï¼Œè¾“å‡ºå±‚å°±æœ‰å‡ ä¸ªç¥ç»å…ƒ, è¾“å‡ºå±‚åªæœ‰ä¸€å±‚ã€‚

**ç¥ç»ç½‘ç»œçš„é‡è¦æ¦‚å¿µ** 

- è¾“å…¥
- è¾“å‡º
- æ¿€æ´»å‡½æ•°
- å‚æ•°


> Q: å…¨è¿æ¥ç¥ç»ç½‘ç»œä¸­æŸä¸€å±‚çš„è¾“å…¥è¾“å‡ºç»´åº¦å¦‚ä½•ç¡®å®š <br>
> A: è¾“å…¥ç»´åº¦ç”±ä¸Šä¸€å±‚ç¥ç»å…ƒä¸ªæ•°ç¡®å®šï¼Œè¾“å‡ºç»´åº¦ç”±æœ¬å±‚ç¥ç»å…ƒç¡®å®š 

**è¾“å…¥è¾“å‡º** 

$H_i^{(i)}$ ä¸‹æ ‡ i è¡¨ç¤ºç¬¬ä¸ªç¥ç»åŸï¼Œä¸Šæ ‡ 1 è¡¨ç¤ºåœ¨ç¬¬ I å±‚, æ•´ä¸ªè¡¨è¾¾å¼å«æ„ä¸º ç¬¬ I å±‚
ç¬¬ i ä¸ªç¥ç»å…ƒçš„å€¼

$w_{i j}^{(k)}$  i è¡¨ç¤ºå‰ä¸€å±‚ç¥ç»å…ƒçš„ä½ç½®ï¼Œ j è¡¨ç¤ºåä¸€å±‚ç¥ç»å…ƒçš„ä½ç½®ï¼Œk è¡¨ç¤ºåœ¨ç¬¬ k å±‚
æ•´ä¸ªè¡¨è¾¾å¼çš„å«æ„ä¸º ä» k - 1 å±‚ çš„ ç¬¬ i ä¸ªç¥ç»å…ƒ åˆ° k çš„ç¬¬ j ä¸ªç¥ç»å…ƒçš„æƒå€¼


$b_i^{(i)}$ ä¸‹æ ‡ i è¡¨ç¤ºç¬¬ä¸ªç¥ç»åŸï¼Œä¸Šæ ‡ i è¡¨ç¤ºåœ¨ç¬¬ i å±‚, æ•´ä¸ªè¡¨è¾¾å¼å«æ„ä¸º ç¬¬ i å±‚
ç¬¬ i ä¸ªç¥ç»å…ƒçš„åç½®çš„å€¼ 

è®¡ç®—å…¬å¼

çŸ©é˜µå½¢å¼ï¼š

$$
h^{(i)} = h^{(i - 1)} \cdot W^{(i)} + b^{(i)}
$$

å±•å¼€ï¼š

$$
(h_1^{(i)} ,h_2^{(i)}, \cdots h_n^{(i)}) = (h_1^{(i-1)} ,h_2^{(i-1)}, \cdots h_m^{(i-1)})  
\begin{bmatrix}
w_{11}^{(i)} & \dots & w_{1n}^{(i)}\\
  & \ddots & \vdots\\
w_{m1}^{(i)} & & w_{mn}^{(i)}
\end{bmatrix} + (b_1^{(i)} ,b_2^{(i)}, \cdots b_n^{(i)})
$$

**æ¿€æ´»å‡½æ•°**

å¸¸è§çš„æ¿€æ´»å‡½æ•°æœ‰

- `softmax`  $\frac{1}{1 + e^{-x}}$  
- `tan(h(x))` $tan(x)$ 
- `ReLU` max(0, x)


$$
h^{(i)} = f(h^{(i - 1)} \cdot W^{(i)} + b^{(i)})
$$

> Q: æ¿€æ´»å‡½æ•°çš„ä½œç”¨æ˜¯ä»€ä¹ˆ
> <br>A: å¯¹ç¥ç»ç½‘ç»œåŠ å…¥éçº¿æ€§æ“ä½œï¼Œå¢å¼ºç¥ç»ç½‘ç»œçš„æ‹Ÿåˆèƒ½åŠ›ï¼Œ
> å¦‚æœä¸åŠ å…¥æ¿€æ´»å‡½æ•°ï¼Œé‚£ä¹ˆéšè—å±‚å°†é€€åŒ–ä¸ºä¸€å±‚

æœ€åå¯¹è¾“å…¥é‡‡ç”¨ `softmax` å‡½æ•°è¿›è¡Œå¤„ç†ã€‚(ä¿è¯æ•°æ®èŒƒå›´åœ¨ (0, 1) å†…, ä¸”æ‰€æœ‰è¾“å‡ºçš„å€¼ç›¸åŠ ä¸ºä¸€)

**å¸¸è§è®­ç»ƒæ¨¡å‹** 

![model](../img/model.png)

**ç¥ç»ç½‘ç»œ-å‚æ•°** 

å…¨ç›¸è¿ç¥ç»ç½‘ç»œçš„å‚æ•°åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œæƒé‡å’Œå‚æ•°

æƒé‡æ•° = ä¸Šä¸€å±‚ç¥ç»å…ƒ * æœ¬å±‚ç¥ç»å…ƒ
åç½®æ•° = æœ¬å±‚ç¥ç»å…ƒæ•°é‡ 

è®­ç»ƒç½‘ç»œç›®çš„å°±æ˜¯äº†æ‰¾åˆ°åˆé€‚çš„æƒé‡å’Œåç½®

**è®­ç»ƒæµç¨‹** 

åˆå§‹åŒ–å‚æ•°: é«˜æ–¯éšæœº

**ç¥ç»ç½‘ç»œè®­ç»ƒæ€»æ½** 

![summary](../img/summary.png)

éšæœºæ¢¯åº¦ğŸ“‰
 
batch: æ‰¹, è®¡ç®—ä¸€ä¸ª batch å³ ä¸€æ¬¡è¿­ä»£
    batch-size


epoch: è½®


![hyperparameter](../img/hyperparameter.png)

éªŒè¯é›†æµ‹è¯•

## lab2

ä½œä¸š: 

![lab2](../img/lab2.png)

é¦–å…ˆæˆ‘ä»¬æ¥å®ç°ä¸€ä¸‹è¯¾ä¸Šæ‰€è®²çš„ MNIST æ•°æ®é›†

- ç¬¬ä¸€æ­¥ å®šä¹‰ç½‘ç»œç»“æ„

æˆ‘ä»¬é¦–å…ˆä»…ä»…è®¾ç½®ä¸€ä¸ªéšè—å±‚

![structure](../img/structure.png)

```py
class FCNet1(nn.modules):
    def __init__(self, **kwargs) -> None:
        super(FCNet1, self).__init__(**kwargs)

        self.hidden = nn.Linear(784, 256)
        self.active = nn.ReLU()
        self.output = nn.Linear(256, 10)

    def forward(self, ../img):
        hidden = self.hidden(../img)
        active = self.active(hidden)
        out = self.output(active)

        return out

```
- åŠ è½½æ•°æ®é›†

```python
train_data = torchvision.datasets.MNIST(root='./data',
                                        train=True,
                                        download=False,
                                        transform=trans)

test_data = torchvision.datasets.MNIST(root='./data',
                                       train=False,
                                       download=False,
                                       transform=trans)

train_data_loader = data.DataLoader(
    dataset=train_data,
    batch_size=200,
    shuffle=True, # æ¯ä¸€æ¬¡ç”¨åŒä¸€ä¸ªbatch éƒ½æ‰“ä¹±é¡ºåº
    num_workers=4 # å·¥ä½œæ ¸å¿ƒ
)

test_data_loader = data.DataLoader(
    dataset=test_data,
    batch_size=200,
    shuffle=False, # æ¯ä¸€æ¬¡ç”¨åŒä¸€ä¸ªbatch éƒ½æ‰“ä¹±é¡ºåº
    num_workers=4 # å·¥ä½œæ ¸å¿ƒ
)

```

- å®šä¹‰ loss function

`loss = nn.CrossEntropyLoss()`

- å®šä¹‰ ä¼˜åŒ–å™¨

`optimizer1 = optim.SGD(net1.parameters(), lr=0.01)`

- å¼€å§‹è®­ç»ƒ

```python

def train(net,
          train_iter,
          test_iter,
          loss,
          num_epochs=10,
          optimizer=None,
          device=None):

    n = 0 # æ€»æ•°
    for epoch in range(1, num_epochs + 1):
        train_loss_sum, train_acc_sum = 0, 0
        for train_images, labels in train_iter:
            # å°†æ•°æ®å­˜æ”¾åœ¨ CPU
            assert isinstance(train_images, torch.Tensor)
            assert isinstance(labels, torch.Tensor)
            # torch.Size([200, 1, 28, 28])
            train_images.to(device)
            labels.to(device)
            # torch.Size([200, 1])

            # forward
            output = net(train_images)

            los = loss(output, labels).sum()

            optimizer.zero_grad()

            # backward
            los.backward()
            optimizer.step()
            train_loss_sum += los

            # argmax(dim=1) è¿”å› ä¸€åˆ—å…ƒç´ æœ€å¤§çš„é‚£ä¸ªä¸‹æ ‡ (200 * 10)
            accruate = (output.argmax(dim=1) == labels).sum().item()
            train_acc_sum += accruate
            n += labels.shape[0]

        test_accuracy = test(net, test_iter)

        print(
            f'epoch {epoch}, train_loss {train_loss_sum / n}, train_accuracy {train_acc_sum / n}, test_accuracy {test_accuracy}'
        )
        n = 0

```

- å¦‚ä½•è°ƒæ•´å­¦ä¹ ç‡

é¦–å…ˆä» 0.01 å¼€å§‹ï¼ŒæŒ‰ç…§ 10 çš„æ¬¡å¹‚å¼€å§‹è°ƒæ•´ã€‚

è°ƒæ•´å¿ƒè·¯å†ç¨‹ `0.01 -> 0.1 -> 0.2 -> 0.15 -> 0.165`



### æœ‰å…³ `autograd`
![dl2](../img/dl2.png)



## å·ç§¯ç¥ç»ç½‘ç»œ

ä½¿ç”¨å…¨è¿æ¥ç¥ç»ç½‘ç»œï¼Œ ä¼šæœ‰å“ªäº›é—®é¢˜?
1. è®¡ç®—é‡å¤ªå¤§ï¼Œå¤æ‚åº¦å¤ªé«˜
2. ä¸¢å¤±å›¾åƒä¿¡æ¯

**å·ç§¯ç¥ç»ç½‘ç»œçš„ç‰¹ç‚¹** 

1. å±€éƒ¨è¿æ¥
2. å‚æ•°å…±äº«

**å·ç§¯æ ¸çš„ä½œç”¨** 

![as](../img/as.png)

**interview** 

> å·ç§¯å±‚çš„å±€éƒ¨è¿æ¥ç‰¹ç‚¹æŒ‡çš„æ˜¯ä»€ä¹ˆ 

ç›¸å½“ä¸ å±€éƒ¨è¿æ¥çš„ å…¨è¿æ¥å±‚, 

> å·ç§¯å±‚çš„å±€éƒ¨è¿æ¥ æœ‰ä»€ä¹ˆå¥½å¤„

å‡å°‘å‚æ•°æ•°ç›®, æå‡è®¡ç®—é€Ÿåº¦

> å·ç§¯å±‚çš„ å‚æ•°å…±äº« ç‰¹ç‚¹æŒ‡çš„æ˜¯ä»€ä¹ˆ 

å¯¹äº ä¸åŒçš„ å›¾åƒä½ç½®,ä½¿ç”¨åŒä¸€ä¸ªå·ç§¯æ ¸ 

> å·ç§¯å±‚çš„ å‚æ•°å…±äº« æœ‰ä»€ä¹ˆå¥½å¤„ 

ä¸ä¼šä¸¢å¤±å›¾åƒçš„å±€éƒ¨ä¿¡æ¯

ç­‰è¾¹è¡¨ç¤º: å±€éƒ¨ç‰¹å¾æ‰€å¤„çš„ä½ç½® ä¸ä¼šå½±å“å·ç§¯çš„ ç»“æœ?

**padding** 

å› ä¸ºç»è¿‡å·ç§¯æ“ä½œå, å¾—åˆ°çš„ç‰¹å¾çŸ©é˜µçš„ç»´æ•°ä¼šå˜å° $m = n - k + 1$,
ä¸ºäº†ä¿è¯ çŸ©é˜µç»´æ•°ä¸å˜, æˆ‘ä»¬å¯ä»¥å…ˆå¯¹çŸ©é˜µè¿›è¡Œå¡«å……å,å†åšå·ç§¯è¿ç®—. $p = \frac{k - 1}{2}$ 

- **Vaild å·ç§¯** ä¸å¡«å…… 

- **Sane å·ç§¯** å¡«å……, ä¸ä¼šä¸¢å¤±å›¾åƒçš„è¾¹ç•Œä¿¡æ¯

**å·ç§¯è¿ç®—æ­¥é•¿** 

è¿›è¡Œè¿ç®—æ—¶, çŸ©é˜µçš„åç§»é‡

**å¤šé€šé“å·ç§¯è¿ç®—** 

åˆ†æˆä¸‰ä¸ªçŸ©é˜µ, åˆ†åˆ«è®¡ç®—å·ç§¯, æœ€åå°†å¯¹åº”ä½ç½®çš„æ•°æ±‚å’Œ.

![dl3](../img/dl3.png)

**æ± åŒ–å±‚** 

![lenet](../img/lenet.png)
![lenet2](../img/lenet2.png)
![lenet3](../img/lenet3.png)
![lenet4](../img/lenet4.png)

- å‡å€¼æ± åŒ–
- æœ€å¤§æ± åŒ–

ä½œç”¨: 
1. å‡å°‘ç‰¹å¾ç»´åº¦, (é™ç»´, å‡å°‘å¤æ‚åº¦)
2. ä¿ç•™ä¸»è¦ç‰¹å¾


## é—®é¢˜

1. `root='./data'`, ä¸è¦å¿˜äº† `.`
2. æœ‰è¶£çš„ `id` å‡½æ•°
    `id` å‡½æ•°è¿”å›çš„å®é™…ä¸Šæ˜¯ å˜é‡æ‰€å‚¨å­˜çš„ å¯¹è±¡çš„ åœ°å€ï¼Œ è€Œä¸æ˜¯è‡ªèº«çš„åœ°å€?

![strangId](../img/strangId.png)

1. why update happens outside the net class ? 
2. where we store the value of the weight parameter ?

```py
for epoch in range(1, num_epoch + 1):
        train_loss_sum, train_acc_sum = 0, 0
        for train_images, labels in train_data_loader:
            # å°†æ•°æ®å­˜æ”¾åœ¨ CPU
            assert isinstance(train_images, torch.Tensor)
            train_images.to(device)
            labels.to(device)

            breakpoint()
            # torch.Size([200, 1, 28, 28])

            # forward
            output = net(train_images)

            los = loss(output, labels).sum()

            optimizer.zero_grad()

            # backward
            los.backward()
            optimizer.step()
            train_loss_sum += los
```

- æ³¨æ„ ä¼˜åŒ–å™¨ ç»‘å®šäº† ä¸€ä¸ªç½‘ç»œçš„ æ‰€æœ‰å‚æ•°ã€‚æ‰€ä»¥ ä¸€ä¸ªä¼˜åŒ–å™¨åªèƒ½å¯¹åº”ä¸€ä¸ª ç½‘ç»œç»“æ„ã€‚å¦‚æœè¦åœ¨ä¸€ä¸ªç¨‹åºä¸­ æµ‹è¯•å¤šä¸ª ç½‘ç»œç»“æ„çš„å‡†ç¡®æ€§ï¼Œå°±éœ€è¦å®šä¹‰å¤šä¸ªç½‘ç»œç»“æ„ã€‚

ä»¥ä¸‹é¢è¿™ä¸ªç½‘ç»œç»“æ„ä¸ºä¾‹

```python
train(net=net1,
          train_iter=train_data_loader,
          test_iter=test_data_loader,
          loss=loss,
          num_epochs=10,
          optimizer=optimizer1,
          device=device)

    print("ç½‘ç»œç»“æ„ 784 - 32 - 16 - 10")
    train(net=net2,
          train_iter=train_data_loader,
          test_iter=test_data_loader,
          loss=loss,
          num_epochs=15,
          optimizer=optimizer1,
          device=device)

```

å¦‚æœ ä¸¤æ¬¡è®­ç»ƒçš„ ä¼˜åŒ–å™¨æ˜¯ä¸€æ ·çš„ï¼Œé‚£ä¹ˆç¬¬äºŒæ¬¡è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œä½ ä¼šå‘ç° æµ‹è¯•å‡†ç¡®ç‡æ˜¯ä¸ªå®šå€¼ã€‚(å› ä¸ºä¼˜åŒ–å™¨åªä¼šæ”¹å˜ç¬¬ä¸€ä¸ªç½‘ç»œç»“æ„çš„å‚æ•°)


1. `lab3` é‡åˆ°çš„é—®é¢˜

- matXX and matXX is not XX. ç½‘ç»œç»“æ„æ²¡è°ƒæ•´å¥½ï¼Œ çŸ©é˜µç›¸ä¹˜æ—¶ï¼Œç»´åº¦å‡ºç°äº†é—®é¢˜
- æ‰“å¼€å›¾ç‰‡, è½¬åŒ–ä¸º tensor, å† å¢åŠ ç»´åº¦  

```python
# æ‰“å¼€å›¾ç‰‡
test_../img = Image.open(path)
test_../img = test_img.convert('L')
data = list(test_../img.getdata())

# è½¬åŒ–ä¸º float32 ç±»å‹
data = np.array(data, np.float32)
data.resize(32, 32)

# å½’ä¸€åŒ–
data /= 255

# æ·»åŠ  ç»´åº¦ 28 * 28 -> 1 * 1 * 28 * 28
trains_../img = torch.from_numpy(data).unsqueeze(0).unsqueeze(0)

```
